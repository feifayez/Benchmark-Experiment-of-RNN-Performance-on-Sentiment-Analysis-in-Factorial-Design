# Benchmark-Experiment-of-RNN-Performance-on-Sentiment-Analysis-in-Factorial-Design
The original study intends to test how the type of pretrained word vector and vocabulary size impact a basic RNN's performance on sentiment analysis. However, the analyst had difficulty to attain fastTex in .txt format and wasn't able to find a solution before the deadline. Therefore, the study was modified to test how vocabulary size and dimension of embedding impact a basic RNN's performance on sentiment analysis. Since the embedding dimension decides the number of inputs of the RNN, this study also exams the impact of RNN design on sentiment analysis result.** 

As mentioned, the study was conducted in a 2x2 factorial design. Factor 1: vocabulary size; Factor 2: dimension of embedding. To satisfy the design, four (4) pretrained word vectors were utilized: gloVe.6b.50d (50 dimensions, 400K vocabulary size), gloVe.6b.100d (100 dimensions, 400K vocabulary size), gloVe.Twitter.50d (50 dimensions, 1.2M vocabulary size), gloVe.Twitter.100d (100 dimensions, 1.2M vocabulary size).** 

The initial analysis of movie reviews data shows that the reviews vary from 22 to 1052 words. It was decided to use the first 20 and last 20 words of each review as the word sequences for analysis. The 500 negative reviews and 500 positive reviews were converted in to a list of 1000 lists of 40 words in each list.**

The 10000 most frequently used words from each of the four (4) embeddings were utilized to construct the embedding to map the preprocessed review data (list of 10000 lists of 40 words) to a numpy array in the shape of (1000, 40, original embedding dimension). This numpy array was used inputs of the RNN. Another numpy array of 500 0s (Thumbs down) and 500 1s (Thumbs up) was constructed as dependent variable. Simple train/test split was used as cross-validation method for this study. 80% of the data was randomly chose as train set while the rest was used as test set.**

A total of (4) tests were run under the 2x2 factor design. Model's accuracy on train set and accuracy on test set were used as performance index. The results show that the basic RNN is prone to overfitting. When the number of inputs was held constant, the RNN designed with embedding compressed from a pre-trained word vector with larger vocabulary provides better predictive accuracy than the one designed with embedding from a smaller vocabulary vector. The result also shows that the RNN model with more inputs, in other words, utilizing embedding of higher dimensions, achieved better predictive accuracy on both train and test set than the one with less inputs (lower dimension).** 

For this study, we preprocessed the review data to include only the first 20 and last 20 words of each review document. We also utilized compressed embeddings instead of the full pre-trained word vectors to build the RNN. We also noticed overfitting with the basic RNN structure. Therefore, as the next step, the management should have data scientists to (1) test RNN performance with different word sequences; (2) test RNN performances with full pre-trained vectors of different vocabulary size; (3) utilize more sophisticated RNN structure including LMST/GRU cell, dropout layer, additional fully-connected layer, etc; (4) consider a multiclass classification where the most critical reviews, either the most positive or the most negative ones, can be identified** 
